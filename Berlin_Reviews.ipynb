{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(7731, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\flari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\flari\\AppData\\Local\\Temp\\ipykernel_16536\\1968675259.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avaliacoes_hoteis.rename(columns= {'reviewTextParts/Liked': 'Good_Comments', 'reviewTextParts/Disliked': 'Bad_Comments'}, inplace= True)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Downloading stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Loading the data\n",
    "### datasource = [Colocar aqui]\n",
    "avaliacoes_hoteis_original = pd.read_csv('./Berlim_All_Reviews.csv')\n",
    "avaliacoes_hoteis = avaliacoes_hoteis_original[['reviewTextParts/Liked', 'reviewTextParts/Disliked']]\n",
    "avaliacoes_hoteis.rename(columns= {'reviewTextParts/Liked': 'Good_Comments', 'reviewTextParts/Disliked': 'Bad_Comments'}, inplace= True)\n",
    "\n",
    "# Object Type\n",
    "print(type(avaliacoes_hoteis))\n",
    "# Shape\n",
    "print(avaliacoes_hoteis.shape)\n",
    "\n",
    "# Selecting the desired columns and converting them to string\n",
    "good_reviews = avaliacoes_hoteis['Good_Comments']\n",
    "good_reviews = good_reviews.astype(str)\n",
    "\n",
    "bad_reviews = avaliacoes_hoteis['Bad_Comments']\n",
    "bad_reviews = bad_reviews.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats the shape of the good reviews in portuguese: (13,)\n",
      "Thats the shape of the bad reviews in portuguese: (13,)\n"
     ]
    }
   ],
   "source": [
    "# Gets the stopwords in all languages\n",
    "dict_stopwords = {lang: set(nltk.corpus.stopwords.words(lang)) for lang in nltk.corpus.stopwords.fileids()}\n",
    "\n",
    "# Function to detect what's the main language using stopwords\n",
    "def find_language(text):\n",
    "    # Tokenization\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    # Count total of tokenized words using the stopwords\n",
    "    lang = max(((lang, len(words & stopwords)) for lang, stopwords in dict_stopwords.items()), key = lambda x:x[1])[0]\n",
    "    # Verifies if it's portuguese\n",
    "    if lang == 'portuguese':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Filters only reviews in portuguese\n",
    "pt_good_reviews = good_reviews[good_reviews.apply(find_language)]\n",
    "pt_bad_reviews = bad_reviews[bad_reviews.apply(find_language)]\n",
    "\n",
    "#Shapes\n",
    "print(f'Thats the shape of the good reviews in portuguese: {pt_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in portuguese: {pt_bad_reviews.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats the shape of the good reviews in english: (482,)\n",
      "Thats the shape of the bad reviews in english: (331,)\n"
     ]
    }
   ],
   "source": [
    "#----------------------- Doing the same thing, but to find the English reviews ------------------------------------------------#\n",
    "\n",
    "# Gets the stopwords in all languages\n",
    "def find_language(text):\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    lang2 = max(((lang2, len(words & stopwords)) for lang2, stopwords in dict_stopwords.items()), key = lambda x:x[1])[0]\n",
    "    # Verifies if it's english\n",
    "    if lang2 == 'english':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "dict_stopwords.pop(\"hinglish\") # Need to pop out otherwise it'll affect the english results\n",
    "  \n",
    "# Filters only reviews in english\n",
    "en_good_reviews = good_reviews[good_reviews.apply(find_language)]\n",
    "en_bad_reviews = bad_reviews[bad_reviews.apply(find_language)]\n",
    "\n",
    "#Shapes\n",
    "print(f'Thats the shape of the good reviews in english: {en_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in english: {en_bad_reviews.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats the shape of the good reviews in german: (1813,)\n",
      "Thats the shape of the bad reviews in german: (1181,)\n"
     ]
    }
   ],
   "source": [
    "#----------------------- Doing the same thing, but to find the German reviews ------------------------------------------------#\n",
    "\n",
    "# Gets the stopwords in all languages\n",
    "def find_language(text):\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    lang3 = max(((lang3, len(words & stopwords)) for lang3, stopwords in dict_stopwords.items()), key = lambda x:x[1])[0]\n",
    "    # Verifies if it's german\n",
    "    if lang3 == 'german':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Filters only reviews in german\n",
    "de_good_reviews = good_reviews[good_reviews.apply(find_language)]\n",
    "de_bad_reviews = bad_reviews[bad_reviews.apply(find_language)]\n",
    "\n",
    "#Shapes\n",
    "print(f'Thats the shape of the good reviews in german: {de_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in german: {de_bad_reviews.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats the shape of the good reviews in french: (55,)\n",
      "Thats the shape of the bad reviews in french: (42,)\n"
     ]
    }
   ],
   "source": [
    "#----------------------- Doing the same thing, but to find the French reviews ------------------------------------------------#\n",
    "\n",
    "# Gets the stopwords in all languages\n",
    "def find_language(text):\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    lang4 = max(((lang4, len(words & stopwords)) for lang4, stopwords in dict_stopwords.items()), key = lambda x:x[1])[0]\n",
    "    # Verifies if it's french\n",
    "    if lang4 == 'french':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Filters only reviews in french\n",
    "fr_good_reviews = good_reviews[good_reviews.apply(find_language)]\n",
    "fr_bad_reviews = bad_reviews[bad_reviews.apply(find_language)]\n",
    "\n",
    "#Shapes\n",
    "print(f'Thats the shape of the good reviews in french: {fr_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in french: {fr_bad_reviews.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats the shape of the good reviews in english: (482,)\n",
      "Thats the shape of the bad reviews in english: (330,)\n",
      "\n",
      "Thats the shape of the good reviews in german: (1806,)\n",
      "Thats the shape of the bad reviews in german: (1120,)\n",
      "\n",
      "Thats the shape of the good reviews in french: (55,)\n",
      "Thats the shape of the bad reviews in french: (42,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dropping duplicates for each dataframe\n",
    "en_good_reviews.drop_duplicates(inplace = True)\n",
    "en_bad_reviews.drop_duplicates(inplace = True)\n",
    "print(f'Thats the shape of the good reviews in english: {en_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in english: {en_bad_reviews.shape}\\n')\n",
    "\n",
    "de_good_reviews.drop_duplicates(inplace = True)\n",
    "de_bad_reviews.drop_duplicates(inplace = True)\n",
    "print(f'Thats the shape of the good reviews in german: {de_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in german: {de_bad_reviews.shape}\\n')\n",
    "\n",
    "fr_good_reviews.drop_duplicates(inplace = True)\n",
    "fr_bad_reviews.drop_duplicates(inplace = True)\n",
    "print(f'Thats the shape of the good reviews in french: {fr_good_reviews.shape}')\n",
    "print(f'Thats the shape of the bad reviews in french: {fr_bad_reviews.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the dictionaries for english, german and french\n",
    "#english\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#german\n",
    "#!python -m spacy download de_core_news_sm\n",
    "#french\n",
    "#!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dictionaries in our SpaCy section\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Function to cleansing and lemmatize the reviews\n",
    "\n",
    "def clean_reviews_en(text):\n",
    "\n",
    "    #Deletes the ponctuation using ReGex\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "\n",
    "    #Using the SpaCy for lemmatization in english\n",
    "    doc = nlp_en(nopunct, disable = ['parser', 'ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def clean_reviews_de(text):\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    #Using the SpaCy for lemmatization in german\n",
    "    doc = nlp_de(nopunct, disable = ['parser', 'ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def clean_reviews_fr(text):\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    #Using the SpaCy for lemmatization in english\n",
    "    doc = nlp_fr(nopunct, disable = ['parser', 'ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applies each function for each language\n",
    "\n",
    "# English\n",
    "en_lemm_good_reviews = en_good_reviews.map(clean_reviews_en)\n",
    "en_lemm_bad_reviews = en_bad_reviews.map(clean_reviews_en)\n",
    "# Lower all the letters\n",
    "en_lemm_good_reviews = en_lemm_good_reviews.map(lambda x: [word.lower() for word in x])\n",
    "en_lemm_bad_reviews = en_lemm_bad_reviews.map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "\n",
    "# german\n",
    "de_lemm_good_reviews = de_good_reviews.map(clean_reviews_de)\n",
    "de_lemm_bad_reviews = de_bad_reviews.map(clean_reviews_de)\n",
    "# Lower all the letters\n",
    "de_lemm_good_reviews = de_lemm_good_reviews.map(lambda x: [word.lower() for word in x])\n",
    "de_lemm_bad_reviews = de_lemm_bad_reviews.map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# french\n",
    "fr_lemm_good_reviews = fr_good_reviews.map(clean_reviews_fr)\n",
    "fr_lemm_bad_reviews = fr_bad_reviews.map(clean_reviews_fr)\n",
    "# Lower all the letters\n",
    "fr_lemm_good_reviews = fr_lemm_good_reviews.map(lambda x: [word.lower() for word in x])\n",
    "fr_lemm_bad_reviews = fr_lemm_bad_reviews.map(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenazing all the reviews\n",
    "# English\n",
    "en_good_reviews_tokens = [item for itens in en_lemm_good_reviews for item in itens]\n",
    "en_bad_reviews_tokens = [item for itens in en_lemm_bad_reviews for item in itens]\n",
    "\n",
    "# German\n",
    "de_good_reviews_tokens = [item for itens in de_lemm_good_reviews for item in itens]\n",
    "de_bad_reviews_tokens = [item for itens in de_lemm_bad_reviews for item in itens]\n",
    "\n",
    "#French\n",
    "fr_good_reviews_tokens = [item for itens in fr_lemm_good_reviews for item in itens]\n",
    "fr_bad_reviews_tokens = [item for itens in fr_lemm_bad_reviews for item in itens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\flari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "## Finding the Trigramas more relevants by Frequency\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# Creating a list with the stopwords, so we can filter them out of our reviews\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "de_stopwords = set(stopwords.words('german'))\n",
    "fr_stopwords = set(stopwords.words('french'))\n",
    "\n",
    "#------------------------ Trigramas for English ------------------#\n",
    "trigrams = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "searchTrigrams_en_good_reviews = nltk.collocations.TrigramCollocationFinder.from_words(en_good_reviews_tokens)\n",
    "searchTrigrams_en_bad_reviews = nltk.collocations.TrigramCollocationFinder.from_words(en_bad_reviews_tokens)\n",
    "\n",
    "# Creating the Pandas Dataframe with the trigrams and its frequency\n",
    "# good reviews\n",
    "trigrams_freq_en_good_reviews = searchTrigrams_en_good_reviews.ngram_fd.items()\n",
    "freqTab_trigram_en_good_reviews = pd.DataFrame(list(trigrams_freq_en_good_reviews),\n",
    "                               columns = ['Trigram_g_en', 'Freq']).sort_values(by= 'Freq', ascending= False)\n",
    "# bad reviews\n",
    "trigrams_freq_en_bad_reviews = searchTrigrams_en_bad_reviews.ngram_fd.items()\n",
    "freqTab_trigram_en_bad_reviews = pd.DataFrame(list(trigrams_freq_en_bad_reviews),\n",
    "                               columns = ['Trigram_b_en', 'Freq']).sort_values(by= 'Freq', ascending= False)\n",
    "\n",
    "\n",
    "#------------------------ Trigramas for German ------------------#\n",
    "searchTrigrams_de_good_reviews = nltk.collocations.TrigramCollocationFinder.from_words(de_good_reviews_tokens)\n",
    "searchTrigrams_de_bad_reviews = nltk.collocations.TrigramCollocationFinder.from_words(de_bad_reviews_tokens)\n",
    "\n",
    "# Creating the Pandas Dataframe with the trigrams and its frequency\n",
    "# good reviews\n",
    "trigrams_freq_de_good_reviews = searchTrigrams_de_good_reviews.ngram_fd.items()\n",
    "freqTab_trigram_de_good_reviews = pd.DataFrame(list(trigrams_freq_de_good_reviews),\n",
    "                               columns = ['Trigram_g_de', 'Freq']).sort_values(by= 'Freq', ascending= False)\n",
    "# bad reviews\n",
    "trigrams_freq_de_bad_reviews = searchTrigrams_de_bad_reviews.ngram_fd.items()\n",
    "freqTab_trigram_de_bad_reviews = pd.DataFrame(list(trigrams_freq_de_bad_reviews),\n",
    "                               columns = ['Trigram_b_de', 'Freq']).sort_values(by= 'Freq', ascending= False)\n",
    "\n",
    "\n",
    "#------------------------ Trigramas for French ------------------#\n",
    "searchTrigrams_fr_good_reviews = nltk.collocations.TrigramCollocationFinder.from_words(fr_good_reviews_tokens)\n",
    "searchTrigrams_fr_bad_reviews = nltk.collocations.TrigramCollocationFinder.from_words(fr_bad_reviews_tokens)\n",
    "\n",
    "# Creating the Pandas Dataframe with the trigrams and its frequency\n",
    "# good reviews\n",
    "trigrams_freq_fr_good_reviews = searchTrigrams_fr_good_reviews.ngram_fd.items()\n",
    "freqTab_trigram_fr_good_reviews = pd.DataFrame(list(trigrams_freq_fr_good_reviews),\n",
    "                               columns = ['Trigram_g_fr', 'Freq']).sort_values(by= 'Freq', ascending= False)\n",
    "# bad reviews\n",
    "trigrams_freq_fr_bad_reviews = searchTrigrams_fr_bad_reviews.ngram_fd.items()\n",
    "freqTab_trigram_fr_bad_reviews = pd.DataFrame(list(trigrams_freq_fr_bad_reviews),\n",
    "                               columns = ['Trigram_b_fr', 'Freq']).sort_values(by= 'Freq', ascending= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter trigrams ADJ/NN and delete the stopwords\n",
    "def filter_type_token_trigram(ngram):\n",
    "    \n",
    "    # check if the work is pronoum\n",
    "    if '-pron-' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    \n",
    "    # Loop in the ngramas to check if they are stopwords in english\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords or word.isspace():\n",
    "            return False\n",
    "    # Loop in the ngramas to check if they are stopwords in german\n",
    "    for word in ngram:\n",
    "        if word in de_stopwords or word.isspace():\n",
    "            return False\n",
    "    # Loop in the ngramas to check if they are stopwords in french\n",
    "    for word in ngram:\n",
    "        if word in fr_stopwords or word.isspace():\n",
    "            return False  \n",
    "\n",
    "        \n",
    "    # Acceptable type of tokens\n",
    "    first_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    \n",
    "    # Subtypes\n",
    "    second_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    \n",
    "    # Tags\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    \n",
    "    # Return what we want, ADJ/NN\n",
    "    if tags[0][1] in first_type and tags[2][1] in second_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Now we can filter our Trigrams by language e type\n",
    "    #English\n",
    "en_good_review_trigrams_filtered = freqTab_trigram_en_good_reviews[freqTab_trigram_en_good_reviews.Trigram_g_en.map(lambda x: filter_type_token_trigram(x))]\n",
    "en_bad_review_trigrams_filtered = freqTab_trigram_en_bad_reviews[freqTab_trigram_en_bad_reviews.Trigram_b_en.map(lambda x: filter_type_token_trigram(x))]\n",
    "\n",
    "    #German\n",
    "de_good_review_trigrams_filtered = freqTab_trigram_de_good_reviews[freqTab_trigram_de_good_reviews.Trigram_g_de.map(lambda x: filter_type_token_trigram(x))]\n",
    "de_bad_review_trigrams_filtered = freqTab_trigram_de_bad_reviews[freqTab_trigram_de_bad_reviews.Trigram_b_de.map(lambda x: filter_type_token_trigram(x))]\n",
    "\n",
    "    #French\n",
    "fr_good_review_trigrams_filtered = freqTab_trigram_fr_good_reviews[freqTab_trigram_fr_good_reviews.Trigram_g_fr.map(lambda x: filter_type_token_trigram(x))]\n",
    "fr_bad_review_trigrams_filtered = freqTab_trigram_fr_bad_reviews[freqTab_trigram_fr_bad_reviews.Trigram_b_fr.map(lambda x: filter_type_token_trigram(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capturing the good reviews of each column for each language\n",
    "en_good_reviews_final = en_good_review_trigrams_filtered[:10].Trigram_g_en.values\n",
    "de_good_reviews_final = de_good_review_trigrams_filtered[:10].Trigram_g_de.values\n",
    "fr_good_reviews_final = fr_good_review_trigrams_filtered[:10].Trigram_g_fr.values\n",
    "\n",
    "#Creating the comparison table for Good Reviews\n",
    "Good_Reviews_Comparison = pd.DataFrame([en_good_reviews_final, de_good_reviews_final, fr_good_reviews_final]).T\n",
    "Good_Reviews_Comparison.columns = ['English', 'German', 'French']\n",
    "Good_Reviews_Comparison.to_excel('Berlin_Good_Reviews.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the same process for the Bad Reviews\n",
    "en_bad_reviews_final = en_bad_review_trigrams_filtered[:10].Trigram_b_en.values\n",
    "de_bad_reviews_final = de_bad_review_trigrams_filtered[:10].Trigram_b_de.values\n",
    "fr_bad_reviews_final = fr_bad_review_trigrams_filtered[:10].Trigram_b_fr.values\n",
    "\n",
    "Bad_Reviews_Comparison = pd.DataFrame([en_bad_reviews_final, de_bad_reviews_final, fr_bad_reviews_final]).T\n",
    "Bad_Reviews_Comparison.columns = ['English', 'German', 'French']\n",
    "Bad_Reviews_Comparison.to_excel('Berlin_Bad_Reviews.xlsx', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlavioEnv1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
